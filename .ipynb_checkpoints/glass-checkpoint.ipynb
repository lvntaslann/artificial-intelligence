{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cd3341-2d19-464e-8437-fc5f4538eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c989b7f8-2e69-492e-8640-f000eb31c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('glass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608869f1-2a3d-4f83-a16d-7137028be260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e4111f-0b2a-4691-9bbf-2f248d24ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      0\n",
       "Na      0\n",
       "Mg      0\n",
       "Al      0\n",
       "Si      0\n",
       "K       0\n",
       "Ca      0\n",
       "Ba      0\n",
       "Fe      0\n",
       "Type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660386f1-905d-4181-8c8e-69b279beae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI      float64\n",
      "Na      float64\n",
      "Mg      float64\n",
      "Al      float64\n",
      "Si      float64\n",
      "K       float64\n",
      "Ca      float64\n",
      "Ba      float64\n",
      "Fe      float64\n",
      "Type      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.astype('float64')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e42716-fd42-40ac-abbc-294db68e933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = df.Type.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506836ef-8855-4705-bd57-cfd4f6a1574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2cc95c-3238-4807-8430-f0631f26bbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 5., 6., 7.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b45c0b-38a4-4aa0-9a4a-d1710b32b2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RI</th>\n",
       "      <td>214.0</td>\n",
       "      <td>1.518365</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>1.51115</td>\n",
       "      <td>1.516522</td>\n",
       "      <td>1.51768</td>\n",
       "      <td>1.519157</td>\n",
       "      <td>1.53393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Na</th>\n",
       "      <td>214.0</td>\n",
       "      <td>13.407850</td>\n",
       "      <td>0.816604</td>\n",
       "      <td>10.73000</td>\n",
       "      <td>12.907500</td>\n",
       "      <td>13.30000</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>17.38000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mg</th>\n",
       "      <td>214.0</td>\n",
       "      <td>2.684533</td>\n",
       "      <td>1.442408</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.115000</td>\n",
       "      <td>3.48000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al</th>\n",
       "      <td>214.0</td>\n",
       "      <td>1.444907</td>\n",
       "      <td>0.499270</td>\n",
       "      <td>0.29000</td>\n",
       "      <td>1.190000</td>\n",
       "      <td>1.36000</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>3.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>214.0</td>\n",
       "      <td>72.650935</td>\n",
       "      <td>0.774546</td>\n",
       "      <td>69.81000</td>\n",
       "      <td>72.280000</td>\n",
       "      <td>72.79000</td>\n",
       "      <td>73.087500</td>\n",
       "      <td>75.41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.652192</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.55500</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>6.21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ca</th>\n",
       "      <td>214.0</td>\n",
       "      <td>8.956963</td>\n",
       "      <td>1.423153</td>\n",
       "      <td>5.43000</td>\n",
       "      <td>8.240000</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>9.172500</td>\n",
       "      <td>16.19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ba</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.497219</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fe</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.51000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>214.0</td>\n",
       "      <td>2.780374</td>\n",
       "      <td>2.103739</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count       mean       std       min        25%       50%        75%  \\\n",
       "RI    214.0   1.518365  0.003037   1.51115   1.516522   1.51768   1.519157   \n",
       "Na    214.0  13.407850  0.816604  10.73000  12.907500  13.30000  13.825000   \n",
       "Mg    214.0   2.684533  1.442408   0.00000   2.115000   3.48000   3.600000   \n",
       "Al    214.0   1.444907  0.499270   0.29000   1.190000   1.36000   1.630000   \n",
       "Si    214.0  72.650935  0.774546  69.81000  72.280000  72.79000  73.087500   \n",
       "K     214.0   0.497056  0.652192   0.00000   0.122500   0.55500   0.610000   \n",
       "Ca    214.0   8.956963  1.423153   5.43000   8.240000   8.60000   9.172500   \n",
       "Ba    214.0   0.175047  0.497219   0.00000   0.000000   0.00000   0.000000   \n",
       "Fe    214.0   0.057009  0.097439   0.00000   0.000000   0.00000   0.100000   \n",
       "Type  214.0   2.780374  2.103739   1.00000   1.000000   2.00000   3.000000   \n",
       "\n",
       "           max  \n",
       "RI     1.53393  \n",
       "Na    17.38000  \n",
       "Mg     4.49000  \n",
       "Al     3.50000  \n",
       "Si    75.41000  \n",
       "K      6.21000  \n",
       "Ca    16.19000  \n",
       "Ba     3.15000  \n",
       "Fe     0.51000  \n",
       "Type   7.00000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae5fda9-98f6-44b2-9dfd-6fed67cf7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c47f71a-6e84-4eb7-8ab9-b754fb19235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Değerler')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type_counts = df['Type'].value_counts()\n",
    "plt.bar(type_counts.index,type_counts,color = \"blue\")\n",
    "plt.title(\"Kategorik veri dağılımı\")\n",
    "plt.xlabel(\"kategoriler\")\n",
    "plt.ylabel(\"Değerler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8afba936-9460-4720-9c64-a263b1c15217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   RI      214 non-null    float64\n",
      " 1   Na      214 non-null    float64\n",
      " 2   Mg      214 non-null    float64\n",
      " 3   Al      214 non-null    float64\n",
      " 4   Si      214 non-null    float64\n",
      " 5   K       214 non-null    float64\n",
      " 6   Ca      214 non-null    float64\n",
      " 7   Ba      214 non-null    float64\n",
      " 8   Fe      214 non-null    float64\n",
      " 9   Type    214 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 16.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36351390-4b2b-4fee-bff4-9f6846e3b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0c0f0c3-a92e-45ec-8aac-660a1b8255d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Type',axis=1)\n",
    "y = df['Type'] -1\n",
    "y=to_categorical(y,num_classes=7)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size=0.80,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54cda9bb-b533-4712-a5b2-755caee8579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9)\n",
      "(171, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f64d65-9e7f-4ad5-a356-76e150a378b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3816cdc0-6a67-4214-98f5-4ed0d8e4d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method compile in module keras.engine.training:\n",
      "\n",
      "compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs) method of keras.engine.sequential.Sequential instance\n",
      "    Configures the model for training.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
      "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
      "                  metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
      "                           tf.keras.metrics.FalseNegatives()])\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "        optimizer: String (name of optimizer) or optimizer instance. See\n",
      "          `tf.keras.optimizers`.\n",
      "        loss: Loss function. May be a string (name of loss function), or\n",
      "          a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
      "          function is any callable with the signature `loss = fn(y_true,\n",
      "          y_pred)`, where `y_true` are the ground truth values, and\n",
      "          `y_pred` are the model's predictions.\n",
      "          `y_true` should have shape\n",
      "          `(batch_size, d0, .. dN)` (except in the case of\n",
      "          sparse loss functions such as\n",
      "          sparse categorical crossentropy which expects integer arrays of\n",
      "          shape `(batch_size, d0, .. dN-1)`).\n",
      "          `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
      "          The loss function should return a float tensor.\n",
      "          If a custom `Loss` instance is\n",
      "          used and reduction is set to `None`, return value has shape\n",
      "          `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
      "          values; otherwise, it is a scalar. If the model has multiple\n",
      "          outputs, you can use a different loss on each output by passing a\n",
      "          dictionary or a list of losses. The loss value that will be\n",
      "          minimized by the model will then be the sum of all individual\n",
      "          losses, unless `loss_weights` is specified.\n",
      "        metrics: List of metrics to be evaluated by the model during\n",
      "          training and testing. Each of this can be a string (name of a\n",
      "          built-in function), function or a `tf.keras.metrics.Metric`\n",
      "          instance. See `tf.keras.metrics`. Typically you will use\n",
      "          `metrics=['accuracy']`.\n",
      "          A function is any callable with the signature `result = fn(y_true,\n",
      "          y_pred)`. To specify different metrics for different outputs of a\n",
      "          multi-output model, you could also pass a dictionary, such as\n",
      "          `metrics={'output_a':'accuracy', 'output_b':['accuracy', 'mse']}`.\n",
      "          You can also pass a list to specify a metric or a list of metrics\n",
      "          for each output, such as\n",
      "          `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
      "          or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
      "          strings 'accuracy' or 'acc', we convert this to one of\n",
      "          `tf.keras.metrics.BinaryAccuracy`,\n",
      "          `tf.keras.metrics.CategoricalAccuracy`,\n",
      "          `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
      "          function used and the model output shape. We do a similar\n",
      "          conversion for the strings 'crossentropy' and 'ce' as well.\n",
      "          The metrics passed here are evaluated without sample weighting; if\n",
      "          you would like sample weighting to apply, you can specify your\n",
      "          metrics via the `weighted_metrics` argument instead.\n",
      "        loss_weights: Optional list or dictionary specifying scalar\n",
      "          coefficients (Python floats) to weight the loss contributions of\n",
      "          different model outputs. The loss value that will be minimized by\n",
      "          the model will then be the *weighted sum* of all individual\n",
      "          losses, weighted by the `loss_weights` coefficients.  If a list,\n",
      "          it is expected to have a 1:1 mapping to the model's outputs. If a\n",
      "          dict, it is expected to map output names (strings) to scalar\n",
      "          coefficients.\n",
      "        weighted_metrics: List of metrics to be evaluated and weighted by\n",
      "          `sample_weight` or `class_weight` during training and testing.\n",
      "        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
      "          logic will not be wrapped in a `tf.function`. Recommended to leave\n",
      "          this as `None` unless your `Model` cannot be run inside a\n",
      "          `tf.function`. `run_eagerly=True` is not supported when using\n",
      "          `tf.distribute.experimental.ParameterServerStrategy`.\n",
      "        steps_per_execution: Int. Defaults to 1. The number of batches to\n",
      "          run during each `tf.function` call. Running multiple batches\n",
      "          inside a single `tf.function` call can greatly improve performance\n",
      "          on TPUs or small models with a large Python overhead. At most, one\n",
      "          full epoch will be run each execution. If a number larger than the\n",
      "          size of the epoch is passed, the execution will be truncated to\n",
      "          the size of the epoch. Note that if `steps_per_execution` is set\n",
      "          to `N`, `Callback.on_batch_begin` and `Callback.on_batch_end`\n",
      "          methods will only be called every `N` batches (i.e. before/after\n",
      "          each `tf.function` execution).\n",
      "        jit_compile: If `True`, compile the model training step with XLA.\n",
      "          [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
      "          for machine learning.\n",
      "          `jit_compile` is not enabled for by default.\n",
      "          This option cannot be enabled with `run_eagerly=True`.\n",
      "          Note that `jit_compile=True`\n",
      "          may not necessarily work for all models.\n",
      "          For more information on supported operations please refer to the\n",
      "          [XLA documentation](https://www.tensorflow.org/xla).\n",
      "          Also refer to\n",
      "          [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
      "          for more details.\n",
      "        **kwargs: Arguments supported for backwards compatibility only.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(model.compile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6243153-2abe-4af5-9dbf-7cc720385498",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45f1a81e-ba07-41a8-be88-b4ed19b22194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6586 - accuracy: 0.7519 - val_loss: 1.4467 - val_accuracy: 0.5952\n",
      "Epoch 2/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7426 - accuracy: 0.6589 - val_loss: 1.3713 - val_accuracy: 0.5714\n",
      "Epoch 3/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6693 - accuracy: 0.7209 - val_loss: 1.5558 - val_accuracy: 0.5238\n",
      "Epoch 4/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7534 - accuracy: 0.6589 - val_loss: 1.4415 - val_accuracy: 0.6190\n",
      "Epoch 5/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6736 - accuracy: 0.7364 - val_loss: 1.3244 - val_accuracy: 0.5238\n",
      "Epoch 6/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.6977 - val_loss: 1.3431 - val_accuracy: 0.6429\n",
      "Epoch 7/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6893 - accuracy: 0.6512 - val_loss: 1.4568 - val_accuracy: 0.5952\n",
      "Epoch 8/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6815 - accuracy: 0.7209 - val_loss: 1.4589 - val_accuracy: 0.5952\n",
      "Epoch 9/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6736 - accuracy: 0.6899 - val_loss: 1.3579 - val_accuracy: 0.6429\n",
      "Epoch 10/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.6899 - val_loss: 1.3045 - val_accuracy: 0.6190\n",
      "Epoch 11/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7183 - accuracy: 0.6357 - val_loss: 1.5364 - val_accuracy: 0.5714\n",
      "Epoch 12/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6861 - accuracy: 0.6977 - val_loss: 1.5094 - val_accuracy: 0.4762\n",
      "Epoch 13/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7877 - accuracy: 0.6744 - val_loss: 1.4992 - val_accuracy: 0.5476\n",
      "Epoch 14/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7930 - accuracy: 0.6512 - val_loss: 1.2431 - val_accuracy: 0.5714\n",
      "Epoch 15/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.7209 - val_loss: 1.4199 - val_accuracy: 0.5952\n",
      "Epoch 16/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7207 - accuracy: 0.6744 - val_loss: 1.3934 - val_accuracy: 0.5952\n",
      "Epoch 17/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7054 - val_loss: 1.4148 - val_accuracy: 0.6429\n",
      "Epoch 18/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6899 - accuracy: 0.6899 - val_loss: 1.3745 - val_accuracy: 0.5000\n",
      "Epoch 19/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7435 - accuracy: 0.6202 - val_loss: 1.3799 - val_accuracy: 0.6190\n",
      "Epoch 20/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6861 - accuracy: 0.6899 - val_loss: 1.4359 - val_accuracy: 0.6190\n",
      "Epoch 21/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.6977 - val_loss: 1.3717 - val_accuracy: 0.6429\n",
      "Epoch 22/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.7287 - val_loss: 1.4315 - val_accuracy: 0.6429\n",
      "Epoch 23/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.6977 - val_loss: 1.4039 - val_accuracy: 0.5714\n",
      "Epoch 24/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.6744 - val_loss: 1.4083 - val_accuracy: 0.5476\n",
      "Epoch 25/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.6512 - val_loss: 1.5147 - val_accuracy: 0.5476\n",
      "Epoch 26/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7247 - accuracy: 0.6357 - val_loss: 1.4060 - val_accuracy: 0.5952\n",
      "Epoch 27/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7282 - accuracy: 0.6279 - val_loss: 1.5749 - val_accuracy: 0.5238\n",
      "Epoch 28/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7064 - accuracy: 0.6124 - val_loss: 1.3573 - val_accuracy: 0.6667\n",
      "Epoch 29/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7062 - accuracy: 0.7054 - val_loss: 1.3436 - val_accuracy: 0.6667\n",
      "Epoch 30/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.6822 - val_loss: 1.5596 - val_accuracy: 0.5952\n",
      "Epoch 31/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7329 - accuracy: 0.6434 - val_loss: 1.5294 - val_accuracy: 0.5476\n",
      "Epoch 32/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.7209 - val_loss: 1.3765 - val_accuracy: 0.5714\n",
      "Epoch 33/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.7364 - val_loss: 1.5230 - val_accuracy: 0.6190\n",
      "Epoch 34/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7054 - val_loss: 1.3540 - val_accuracy: 0.6429\n",
      "Epoch 35/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.6899 - val_loss: 1.3755 - val_accuracy: 0.6667\n",
      "Epoch 36/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7054 - val_loss: 1.4361 - val_accuracy: 0.6190\n",
      "Epoch 37/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.7287 - val_loss: 1.3754 - val_accuracy: 0.6190\n",
      "Epoch 38/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.6977 - val_loss: 1.4074 - val_accuracy: 0.6667\n",
      "Epoch 39/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8144 - accuracy: 0.6124 - val_loss: 1.5953 - val_accuracy: 0.5238\n",
      "Epoch 40/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.6589 - val_loss: 1.3948 - val_accuracy: 0.5714\n",
      "Epoch 41/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7665 - accuracy: 0.6589 - val_loss: 1.4737 - val_accuracy: 0.5476\n",
      "Epoch 42/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8495 - accuracy: 0.6124 - val_loss: 1.4977 - val_accuracy: 0.5952\n",
      "Epoch 43/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7508 - accuracy: 0.6512 - val_loss: 1.4159 - val_accuracy: 0.5000\n",
      "Epoch 44/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7946 - accuracy: 0.6279 - val_loss: 1.4430 - val_accuracy: 0.5952\n",
      "Epoch 45/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7357 - accuracy: 0.6899 - val_loss: 1.2675 - val_accuracy: 0.5952\n",
      "Epoch 46/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7287 - val_loss: 1.2768 - val_accuracy: 0.5476\n",
      "Epoch 47/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7377 - accuracy: 0.6124 - val_loss: 1.3922 - val_accuracy: 0.5714\n",
      "Epoch 48/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7515 - accuracy: 0.6667 - val_loss: 1.2771 - val_accuracy: 0.5714\n",
      "Epoch 49/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6845 - accuracy: 0.7364 - val_loss: 1.3530 - val_accuracy: 0.5000\n",
      "Epoch 50/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7316 - accuracy: 0.6279 - val_loss: 1.3330 - val_accuracy: 0.6429\n",
      "Epoch 51/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.7209 - val_loss: 1.3134 - val_accuracy: 0.6190\n",
      "Epoch 52/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6562 - accuracy: 0.7054 - val_loss: 1.3725 - val_accuracy: 0.6190\n",
      "Epoch 53/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.6667 - val_loss: 1.3419 - val_accuracy: 0.6667\n",
      "Epoch 54/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.7132 - val_loss: 1.2188 - val_accuracy: 0.5952\n",
      "Epoch 55/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7805 - accuracy: 0.6977 - val_loss: 1.3841 - val_accuracy: 0.5952\n",
      "Epoch 56/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6610 - accuracy: 0.6977 - val_loss: 1.6424 - val_accuracy: 0.5238\n",
      "Epoch 57/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7195 - accuracy: 0.6357 - val_loss: 1.4357 - val_accuracy: 0.5238\n",
      "Epoch 58/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.6822 - val_loss: 1.4525 - val_accuracy: 0.6429\n",
      "Epoch 59/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.6977 - val_loss: 1.5131 - val_accuracy: 0.6190\n",
      "Epoch 60/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.7054 - val_loss: 1.5208 - val_accuracy: 0.5238\n",
      "Epoch 61/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.6899 - val_loss: 1.4364 - val_accuracy: 0.5238\n",
      "Epoch 62/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.6589 - val_loss: 1.3360 - val_accuracy: 0.6429\n",
      "Epoch 63/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6754 - accuracy: 0.7287 - val_loss: 1.2760 - val_accuracy: 0.5476\n",
      "Epoch 64/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8032 - accuracy: 0.6279 - val_loss: 1.6369 - val_accuracy: 0.5000\n",
      "Epoch 65/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.6822 - val_loss: 1.4732 - val_accuracy: 0.5476\n",
      "Epoch 66/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.7209 - val_loss: 1.2894 - val_accuracy: 0.6667\n",
      "Epoch 67/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7442 - val_loss: 1.3289 - val_accuracy: 0.6905\n",
      "Epoch 68/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6318 - accuracy: 0.7364 - val_loss: 1.2940 - val_accuracy: 0.6429\n",
      "Epoch 69/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.6977 - val_loss: 1.4424 - val_accuracy: 0.6190\n",
      "Epoch 70/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.7287 - val_loss: 1.5184 - val_accuracy: 0.5714\n",
      "Epoch 71/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7370 - accuracy: 0.6279 - val_loss: 1.4564 - val_accuracy: 0.6190\n",
      "Epoch 72/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7093 - accuracy: 0.6512 - val_loss: 1.3460 - val_accuracy: 0.5714\n",
      "Epoch 73/512\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6899 - val_loss: 1.5261 - val_accuracy: 0.5476\n",
      "Epoch 74/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6449 - accuracy: 0.6977 - val_loss: 1.3122 - val_accuracy: 0.5952\n",
      "Epoch 75/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.6977 - val_loss: 1.3124 - val_accuracy: 0.5952\n",
      "Epoch 76/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.6977 - val_loss: 1.4932 - val_accuracy: 0.5714\n",
      "Epoch 77/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.7054 - val_loss: 1.4461 - val_accuracy: 0.5476\n",
      "Epoch 78/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7358 - accuracy: 0.6357 - val_loss: 1.5326 - val_accuracy: 0.5714\n",
      "Epoch 79/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.6822 - val_loss: 1.3165 - val_accuracy: 0.5952\n",
      "Epoch 80/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.7054 - val_loss: 1.4041 - val_accuracy: 0.6429\n",
      "Epoch 81/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.7519 - val_loss: 1.4825 - val_accuracy: 0.5952\n",
      "Epoch 82/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.6977 - val_loss: 1.3030 - val_accuracy: 0.6190\n",
      "Epoch 83/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7484 - accuracy: 0.6512 - val_loss: 1.5493 - val_accuracy: 0.5714\n",
      "Epoch 84/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8118 - accuracy: 0.6124 - val_loss: 1.3189 - val_accuracy: 0.5238\n",
      "Epoch 85/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.6667 - val_loss: 1.4778 - val_accuracy: 0.5000\n",
      "Epoch 86/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7357 - accuracy: 0.6434 - val_loss: 1.2857 - val_accuracy: 0.6190\n",
      "Epoch 87/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6538 - accuracy: 0.7519 - val_loss: 1.3311 - val_accuracy: 0.6190\n",
      "Epoch 88/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.7054 - val_loss: 1.2568 - val_accuracy: 0.6429\n",
      "Epoch 89/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7102 - accuracy: 0.6124 - val_loss: 1.2722 - val_accuracy: 0.6429\n",
      "Epoch 90/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.7519 - val_loss: 1.3433 - val_accuracy: 0.6429\n",
      "Epoch 91/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.7132 - val_loss: 1.3790 - val_accuracy: 0.6429\n",
      "Epoch 92/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.7597 - val_loss: 1.4491 - val_accuracy: 0.6190\n",
      "Epoch 93/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6801 - accuracy: 0.6667 - val_loss: 1.3351 - val_accuracy: 0.5952\n",
      "Epoch 94/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.6744 - val_loss: 1.4169 - val_accuracy: 0.6190\n",
      "Epoch 95/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6899 - val_loss: 1.3613 - val_accuracy: 0.5714\n",
      "Epoch 96/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.6434 - val_loss: 1.3809 - val_accuracy: 0.6667\n",
      "Epoch 97/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.7442 - val_loss: 1.3612 - val_accuracy: 0.6667\n",
      "Epoch 98/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8311 - accuracy: 0.6357 - val_loss: 1.3718 - val_accuracy: 0.5952\n",
      "Epoch 99/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.7054 - val_loss: 1.7002 - val_accuracy: 0.4762\n",
      "Epoch 100/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7506 - accuracy: 0.6357 - val_loss: 1.4480 - val_accuracy: 0.6667\n",
      "Epoch 101/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.6667 - val_loss: 1.3476 - val_accuracy: 0.6667\n",
      "Epoch 102/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.7519 - val_loss: 1.4224 - val_accuracy: 0.6429\n",
      "Epoch 103/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.7209 - val_loss: 1.3776 - val_accuracy: 0.6429\n",
      "Epoch 104/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.6744 - val_loss: 1.4020 - val_accuracy: 0.6667\n",
      "Epoch 105/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.6744 - val_loss: 1.4540 - val_accuracy: 0.6190\n",
      "Epoch 106/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.7209 - val_loss: 1.3721 - val_accuracy: 0.5952\n",
      "Epoch 107/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7054 - accuracy: 0.6667 - val_loss: 1.4575 - val_accuracy: 0.6190\n",
      "Epoch 108/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.6589 - val_loss: 1.3844 - val_accuracy: 0.6429\n",
      "Epoch 109/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6534 - accuracy: 0.7054 - val_loss: 1.3360 - val_accuracy: 0.6190\n",
      "Epoch 110/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.6899 - val_loss: 1.2831 - val_accuracy: 0.6429\n",
      "Epoch 111/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6885 - accuracy: 0.6512 - val_loss: 1.3932 - val_accuracy: 0.6667\n",
      "Epoch 112/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7834 - accuracy: 0.6124 - val_loss: 1.3701 - val_accuracy: 0.6190\n",
      "Epoch 113/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6219 - accuracy: 0.7519 - val_loss: 1.5824 - val_accuracy: 0.5476\n",
      "Epoch 114/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.7132 - val_loss: 1.3771 - val_accuracy: 0.5714\n",
      "Epoch 115/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6551 - accuracy: 0.6899 - val_loss: 1.4080 - val_accuracy: 0.6667\n",
      "Epoch 116/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6536 - accuracy: 0.7054 - val_loss: 1.5906 - val_accuracy: 0.5476\n",
      "Epoch 117/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.6667 - val_loss: 1.3447 - val_accuracy: 0.6190\n",
      "Epoch 118/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.6434 - val_loss: 1.4537 - val_accuracy: 0.6190\n",
      "Epoch 119/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.7132 - val_loss: 1.3543 - val_accuracy: 0.6190\n",
      "Epoch 120/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6667 - val_loss: 1.5066 - val_accuracy: 0.6429\n",
      "Epoch 121/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.6899 - val_loss: 1.4293 - val_accuracy: 0.4762\n",
      "Epoch 122/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.7209 - val_loss: 1.4806 - val_accuracy: 0.6429\n",
      "Epoch 123/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.7287 - val_loss: 1.3982 - val_accuracy: 0.6429\n",
      "Epoch 124/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.7442 - val_loss: 1.3904 - val_accuracy: 0.6667\n",
      "Epoch 125/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.7597 - val_loss: 1.4619 - val_accuracy: 0.6190\n",
      "Epoch 126/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6001 - accuracy: 0.7442 - val_loss: 1.5087 - val_accuracy: 0.6667\n",
      "Epoch 127/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.7054 - val_loss: 1.4486 - val_accuracy: 0.5952\n",
      "Epoch 128/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.7132 - val_loss: 1.6506 - val_accuracy: 0.5476\n",
      "Epoch 129/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6426 - accuracy: 0.6977 - val_loss: 1.5968 - val_accuracy: 0.6667\n",
      "Epoch 130/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.7132 - val_loss: 1.5544 - val_accuracy: 0.6905\n",
      "Epoch 131/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5862 - accuracy: 0.7597 - val_loss: 1.5305 - val_accuracy: 0.6429\n",
      "Epoch 132/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.7442 - val_loss: 1.5842 - val_accuracy: 0.6190\n",
      "Epoch 133/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5828 - accuracy: 0.7829 - val_loss: 1.5051 - val_accuracy: 0.6905\n",
      "Epoch 134/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.7209 - val_loss: 1.4552 - val_accuracy: 0.5952\n",
      "Epoch 135/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.7132 - val_loss: 1.4089 - val_accuracy: 0.6190\n",
      "Epoch 136/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.7752 - val_loss: 1.7805 - val_accuracy: 0.5714\n",
      "Epoch 137/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7380 - accuracy: 0.6977 - val_loss: 1.5594 - val_accuracy: 0.5238\n",
      "Epoch 138/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7909 - accuracy: 0.6357 - val_loss: 1.7809 - val_accuracy: 0.5476\n",
      "Epoch 139/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8049 - accuracy: 0.6202 - val_loss: 1.8540 - val_accuracy: 0.5000\n",
      "Epoch 140/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7371 - accuracy: 0.7209 - val_loss: 1.5236 - val_accuracy: 0.6190\n",
      "Epoch 141/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7105 - accuracy: 0.7364 - val_loss: 1.5098 - val_accuracy: 0.5952\n",
      "Epoch 142/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.7287 - val_loss: 1.5561 - val_accuracy: 0.5714\n",
      "Epoch 143/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7597 - val_loss: 1.4067 - val_accuracy: 0.6429\n",
      "Epoch 144/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.7287 - val_loss: 1.5111 - val_accuracy: 0.6190\n",
      "Epoch 145/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.7597 - val_loss: 1.4079 - val_accuracy: 0.6429\n",
      "Epoch 146/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6347 - accuracy: 0.7132 - val_loss: 1.4710 - val_accuracy: 0.6190\n",
      "Epoch 147/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7450 - accuracy: 0.6434 - val_loss: 1.6773 - val_accuracy: 0.5238\n",
      "Epoch 148/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.6899 - val_loss: 1.7030 - val_accuracy: 0.5714\n",
      "Epoch 149/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.6512 - val_loss: 1.5193 - val_accuracy: 0.5714\n",
      "Epoch 150/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.7364 - val_loss: 1.5048 - val_accuracy: 0.6190\n",
      "Epoch 151/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6041 - accuracy: 0.7442 - val_loss: 1.5034 - val_accuracy: 0.6667\n",
      "Epoch 152/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.7209 - val_loss: 1.4952 - val_accuracy: 0.6429\n",
      "Epoch 153/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.7364 - val_loss: 1.4943 - val_accuracy: 0.6667\n",
      "Epoch 154/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.7209 - val_loss: 1.3569 - val_accuracy: 0.6667\n",
      "Epoch 155/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.7442 - val_loss: 1.5051 - val_accuracy: 0.6190\n",
      "Epoch 156/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7242 - accuracy: 0.6744 - val_loss: 1.4963 - val_accuracy: 0.5952\n",
      "Epoch 157/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.6822 - val_loss: 1.2691 - val_accuracy: 0.6667\n",
      "Epoch 158/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5944 - accuracy: 0.7519 - val_loss: 1.3358 - val_accuracy: 0.6667\n",
      "Epoch 159/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.7054 - val_loss: 1.4533 - val_accuracy: 0.6667\n",
      "Epoch 160/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.7442 - val_loss: 1.3751 - val_accuracy: 0.6905\n",
      "Epoch 161/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.7519 - val_loss: 1.3264 - val_accuracy: 0.6190\n",
      "Epoch 162/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7248 - accuracy: 0.6589 - val_loss: 1.5588 - val_accuracy: 0.6905\n",
      "Epoch 163/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6129 - accuracy: 0.7364 - val_loss: 1.4718 - val_accuracy: 0.6190\n",
      "Epoch 164/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6893 - accuracy: 0.6822 - val_loss: 1.5344 - val_accuracy: 0.6905\n",
      "Epoch 165/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.7519 - val_loss: 1.4057 - val_accuracy: 0.6190\n",
      "Epoch 166/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5871 - accuracy: 0.7287 - val_loss: 1.4201 - val_accuracy: 0.6905\n",
      "Epoch 167/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5694 - accuracy: 0.7519 - val_loss: 1.5016 - val_accuracy: 0.6905\n",
      "Epoch 168/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.7597 - val_loss: 1.5681 - val_accuracy: 0.6429\n",
      "Epoch 169/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7442 - val_loss: 1.4826 - val_accuracy: 0.6905\n",
      "Epoch 170/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7752 - val_loss: 1.4595 - val_accuracy: 0.6905\n",
      "Epoch 171/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5818 - accuracy: 0.7597 - val_loss: 1.4604 - val_accuracy: 0.6429\n",
      "Epoch 172/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5715 - accuracy: 0.7674 - val_loss: 1.6559 - val_accuracy: 0.6190\n",
      "Epoch 173/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 0.7054 - val_loss: 1.5859 - val_accuracy: 0.6905\n",
      "Epoch 174/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9354 - accuracy: 0.5969 - val_loss: 1.7889 - val_accuracy: 0.5238\n",
      "Epoch 175/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7072 - accuracy: 0.6744 - val_loss: 1.5792 - val_accuracy: 0.5238\n",
      "Epoch 176/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7506 - accuracy: 0.7209 - val_loss: 1.5044 - val_accuracy: 0.5238\n",
      "Epoch 177/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6665 - accuracy: 0.6977 - val_loss: 1.4988 - val_accuracy: 0.5952\n",
      "Epoch 178/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6139 - accuracy: 0.7442 - val_loss: 1.4531 - val_accuracy: 0.6667\n",
      "Epoch 179/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6106 - accuracy: 0.7209 - val_loss: 1.4371 - val_accuracy: 0.5952\n",
      "Epoch 180/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6059 - accuracy: 0.7287 - val_loss: 1.5615 - val_accuracy: 0.6667\n",
      "Epoch 181/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6052 - accuracy: 0.7442 - val_loss: 1.5143 - val_accuracy: 0.5238\n",
      "Epoch 182/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6747 - accuracy: 0.7132 - val_loss: 1.5721 - val_accuracy: 0.6667\n",
      "Epoch 183/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6324 - accuracy: 0.7132 - val_loss: 1.5263 - val_accuracy: 0.6190\n",
      "Epoch 184/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.7519 - val_loss: 1.5234 - val_accuracy: 0.6905\n",
      "Epoch 185/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6011 - accuracy: 0.7442 - val_loss: 1.5791 - val_accuracy: 0.6667\n",
      "Epoch 186/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5606 - accuracy: 0.7829 - val_loss: 1.5613 - val_accuracy: 0.6905\n",
      "Epoch 187/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.7442 - val_loss: 1.4964 - val_accuracy: 0.6667\n",
      "Epoch 188/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5649 - accuracy: 0.7674 - val_loss: 1.6313 - val_accuracy: 0.6905\n",
      "Epoch 189/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.7132 - val_loss: 1.5511 - val_accuracy: 0.5476\n",
      "Epoch 190/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7307 - accuracy: 0.6589 - val_loss: 1.5332 - val_accuracy: 0.6190\n",
      "Epoch 191/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.7209 - val_loss: 1.6298 - val_accuracy: 0.6190\n",
      "Epoch 192/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.7442 - val_loss: 1.7042 - val_accuracy: 0.5714\n",
      "Epoch 193/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6324 - accuracy: 0.7132 - val_loss: 1.5225 - val_accuracy: 0.6429\n",
      "Epoch 194/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.7209 - val_loss: 1.4314 - val_accuracy: 0.6429\n",
      "Epoch 195/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.7674 - val_loss: 1.6512 - val_accuracy: 0.5476\n",
      "Epoch 196/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.6744 - val_loss: 1.8036 - val_accuracy: 0.5714\n",
      "Epoch 197/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6049 - accuracy: 0.7132 - val_loss: 1.5605 - val_accuracy: 0.5714\n",
      "Epoch 198/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5814 - accuracy: 0.7132 - val_loss: 1.5697 - val_accuracy: 0.6429\n",
      "Epoch 199/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6155 - accuracy: 0.7519 - val_loss: 1.5763 - val_accuracy: 0.6429\n",
      "Epoch 200/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7674 - val_loss: 1.5767 - val_accuracy: 0.6667\n",
      "Epoch 201/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.7054 - val_loss: 1.5606 - val_accuracy: 0.6667\n",
      "Epoch 202/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5660 - accuracy: 0.7597 - val_loss: 1.5589 - val_accuracy: 0.6667\n",
      "Epoch 203/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.7752 - val_loss: 1.6251 - val_accuracy: 0.6667\n",
      "Epoch 204/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7364 - val_loss: 1.7006 - val_accuracy: 0.6905\n",
      "Epoch 205/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6286 - accuracy: 0.6977 - val_loss: 1.6379 - val_accuracy: 0.5952\n",
      "Epoch 206/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6739 - accuracy: 0.6822 - val_loss: 1.7499 - val_accuracy: 0.6667\n",
      "Epoch 207/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6001 - accuracy: 0.7209 - val_loss: 1.5139 - val_accuracy: 0.5952\n",
      "Epoch 208/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5967 - accuracy: 0.7132 - val_loss: 1.8329 - val_accuracy: 0.6190\n",
      "Epoch 209/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6307 - accuracy: 0.6744 - val_loss: 1.6269 - val_accuracy: 0.5476\n",
      "Epoch 210/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.2329 - accuracy: 0.6124 - val_loss: 1.8819 - val_accuracy: 0.5238\n",
      "Epoch 211/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.9335 - accuracy: 0.6124 - val_loss: 1.6584 - val_accuracy: 0.5476\n",
      "Epoch 212/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7561 - accuracy: 0.6589 - val_loss: 1.3701 - val_accuracy: 0.6429\n",
      "Epoch 213/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7744 - accuracy: 0.6667 - val_loss: 1.3621 - val_accuracy: 0.6667\n",
      "Epoch 214/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7104 - accuracy: 0.6744 - val_loss: 1.3684 - val_accuracy: 0.6429\n",
      "Epoch 215/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6758 - accuracy: 0.7054 - val_loss: 1.4205 - val_accuracy: 0.6667\n",
      "Epoch 216/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6516 - accuracy: 0.7442 - val_loss: 1.4883 - val_accuracy: 0.6667\n",
      "Epoch 217/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6685 - accuracy: 0.7132 - val_loss: 1.4979 - val_accuracy: 0.6667\n",
      "Epoch 218/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.6977 - val_loss: 1.5216 - val_accuracy: 0.6667\n",
      "Epoch 219/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6853 - accuracy: 0.6589 - val_loss: 1.4955 - val_accuracy: 0.6667\n",
      "Epoch 220/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6165 - accuracy: 0.7442 - val_loss: 1.4419 - val_accuracy: 0.6190\n",
      "Epoch 221/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6381 - accuracy: 0.7519 - val_loss: 1.5205 - val_accuracy: 0.6429\n",
      "Epoch 222/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6741 - accuracy: 0.6822 - val_loss: 1.5360 - val_accuracy: 0.6667\n",
      "Epoch 223/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6187 - accuracy: 0.7674 - val_loss: 1.5447 - val_accuracy: 0.6667\n",
      "Epoch 224/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6679 - accuracy: 0.7287 - val_loss: 1.5074 - val_accuracy: 0.6667\n",
      "Epoch 225/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6550 - accuracy: 0.7287 - val_loss: 1.5741 - val_accuracy: 0.6667\n",
      "Epoch 226/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.6977 - val_loss: 1.5638 - val_accuracy: 0.6667\n",
      "Epoch 227/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.8145 - accuracy: 0.6202 - val_loss: 1.7714 - val_accuracy: 0.5476\n",
      "Epoch 228/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7963 - accuracy: 0.5814 - val_loss: 1.4828 - val_accuracy: 0.5952\n",
      "Epoch 229/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6719 - accuracy: 0.6744 - val_loss: 1.6112 - val_accuracy: 0.6667\n",
      "Epoch 230/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7003 - accuracy: 0.6434 - val_loss: 1.5626 - val_accuracy: 0.6667\n",
      "Epoch 231/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7130 - accuracy: 0.6589 - val_loss: 1.5212 - val_accuracy: 0.6905\n",
      "Epoch 232/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7034 - accuracy: 0.6589 - val_loss: 1.5270 - val_accuracy: 0.5714\n",
      "Epoch 233/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.7442 - val_loss: 1.5510 - val_accuracy: 0.6429\n",
      "Epoch 234/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.7674 - val_loss: 1.4713 - val_accuracy: 0.6429\n",
      "Epoch 235/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6174 - accuracy: 0.7364 - val_loss: 1.5508 - val_accuracy: 0.6667\n",
      "Epoch 236/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6218 - accuracy: 0.7054 - val_loss: 1.5124 - val_accuracy: 0.6429\n",
      "Epoch 237/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6239 - accuracy: 0.7287 - val_loss: 1.5542 - val_accuracy: 0.6429\n",
      "Epoch 238/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6120 - accuracy: 0.7364 - val_loss: 1.4583 - val_accuracy: 0.6429\n",
      "Epoch 239/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.7597 - val_loss: 1.5169 - val_accuracy: 0.6667\n",
      "Epoch 240/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5880 - accuracy: 0.7674 - val_loss: 1.5520 - val_accuracy: 0.6667\n",
      "Epoch 241/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6515 - accuracy: 0.6977 - val_loss: 1.5967 - val_accuracy: 0.6667\n",
      "Epoch 242/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6564 - accuracy: 0.7209 - val_loss: 1.4328 - val_accuracy: 0.5952\n",
      "Epoch 243/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7107 - accuracy: 0.6512 - val_loss: 1.5578 - val_accuracy: 0.6429\n",
      "Epoch 244/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6261 - accuracy: 0.7597 - val_loss: 1.5130 - val_accuracy: 0.6190\n",
      "Epoch 245/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7113 - accuracy: 0.6589 - val_loss: 1.5801 - val_accuracy: 0.6667\n",
      "Epoch 246/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7052 - accuracy: 0.6589 - val_loss: 1.6550 - val_accuracy: 0.6190\n",
      "Epoch 247/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.7519 - val_loss: 1.5032 - val_accuracy: 0.5952\n",
      "Epoch 248/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6123 - accuracy: 0.7054 - val_loss: 1.5612 - val_accuracy: 0.6905\n",
      "Epoch 249/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5949 - accuracy: 0.7519 - val_loss: 1.5278 - val_accuracy: 0.6429\n",
      "Epoch 250/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6574 - accuracy: 0.6667 - val_loss: 1.5170 - val_accuracy: 0.6429\n",
      "Epoch 251/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6080 - accuracy: 0.7674 - val_loss: 1.5931 - val_accuracy: 0.6667\n",
      "Epoch 252/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.7752 - val_loss: 1.5922 - val_accuracy: 0.6667\n",
      "Epoch 253/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.7519 - val_loss: 1.6011 - val_accuracy: 0.6429\n",
      "Epoch 254/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.7984 - val_loss: 1.5926 - val_accuracy: 0.6667\n",
      "Epoch 255/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.7674 - val_loss: 1.5457 - val_accuracy: 0.6667\n",
      "Epoch 256/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5646 - accuracy: 0.7752 - val_loss: 1.5997 - val_accuracy: 0.6429\n",
      "Epoch 257/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.7752 - val_loss: 1.6981 - val_accuracy: 0.6429\n",
      "Epoch 258/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.7442 - val_loss: 1.6076 - val_accuracy: 0.5714\n",
      "Epoch 259/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.6977 - val_loss: 1.5740 - val_accuracy: 0.6905\n",
      "Epoch 260/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.7442 - val_loss: 1.5778 - val_accuracy: 0.6190\n",
      "Epoch 261/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.7597 - val_loss: 1.7540 - val_accuracy: 0.6667\n",
      "Epoch 262/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6462 - accuracy: 0.7209 - val_loss: 1.6295 - val_accuracy: 0.6667\n",
      "Epoch 263/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6091 - accuracy: 0.7132 - val_loss: 1.4632 - val_accuracy: 0.6429\n",
      "Epoch 264/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7092 - accuracy: 0.7209 - val_loss: 1.3654 - val_accuracy: 0.6429\n",
      "Epoch 265/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6459 - accuracy: 0.7287 - val_loss: 1.4467 - val_accuracy: 0.6429\n",
      "Epoch 266/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6842 - accuracy: 0.6822 - val_loss: 1.7134 - val_accuracy: 0.6429\n",
      "Epoch 267/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6297 - accuracy: 0.7132 - val_loss: 1.6144 - val_accuracy: 0.5952\n",
      "Epoch 268/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.6899 - val_loss: 1.6137 - val_accuracy: 0.6905\n",
      "Epoch 269/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7364 - val_loss: 1.5616 - val_accuracy: 0.6190\n",
      "Epoch 270/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5813 - accuracy: 0.7209 - val_loss: 1.6430 - val_accuracy: 0.6667\n",
      "Epoch 271/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5934 - accuracy: 0.7519 - val_loss: 1.6523 - val_accuracy: 0.6429\n",
      "Epoch 272/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7597 - val_loss: 1.6984 - val_accuracy: 0.6429\n",
      "Epoch 273/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6391 - accuracy: 0.7054 - val_loss: 1.6588 - val_accuracy: 0.5952\n",
      "Epoch 274/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.7054 - val_loss: 1.7642 - val_accuracy: 0.6429\n",
      "Epoch 275/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5761 - accuracy: 0.7442 - val_loss: 1.7237 - val_accuracy: 0.6429\n",
      "Epoch 276/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5530 - accuracy: 0.7674 - val_loss: 1.7403 - val_accuracy: 0.6667\n",
      "Epoch 277/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6420 - accuracy: 0.7132 - val_loss: 1.5854 - val_accuracy: 0.5952\n",
      "Epoch 278/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6526 - accuracy: 0.6899 - val_loss: 1.8141 - val_accuracy: 0.6667\n",
      "Epoch 279/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6090 - accuracy: 0.7519 - val_loss: 1.9202 - val_accuracy: 0.6667\n",
      "Epoch 280/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6854 - accuracy: 0.6899 - val_loss: 1.8851 - val_accuracy: 0.6190\n",
      "Epoch 281/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.6822 - val_loss: 1.7550 - val_accuracy: 0.6667\n",
      "Epoch 282/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7024 - accuracy: 0.6589 - val_loss: 1.8455 - val_accuracy: 0.5952\n",
      "Epoch 283/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 1.2819 - accuracy: 0.5504 - val_loss: 2.2086 - val_accuracy: 0.5238\n",
      "Epoch 284/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.9522 - accuracy: 0.6512 - val_loss: 1.6216 - val_accuracy: 0.5952\n",
      "Epoch 285/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7639 - accuracy: 0.6667 - val_loss: 1.3937 - val_accuracy: 0.6190\n",
      "Epoch 286/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6982 - accuracy: 0.7442 - val_loss: 1.4014 - val_accuracy: 0.6190\n",
      "Epoch 287/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.7442 - val_loss: 1.3570 - val_accuracy: 0.5952\n",
      "Epoch 288/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6331 - accuracy: 0.7054 - val_loss: 1.3954 - val_accuracy: 0.6429\n",
      "Epoch 289/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7052 - accuracy: 0.6124 - val_loss: 1.4020 - val_accuracy: 0.6667\n",
      "Epoch 290/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6172 - accuracy: 0.7442 - val_loss: 1.3980 - val_accuracy: 0.6429\n",
      "Epoch 291/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5983 - accuracy: 0.7674 - val_loss: 1.4432 - val_accuracy: 0.6667\n",
      "Epoch 292/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5931 - accuracy: 0.7442 - val_loss: 1.3577 - val_accuracy: 0.6429\n",
      "Epoch 293/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5811 - accuracy: 0.7597 - val_loss: 1.3674 - val_accuracy: 0.6429\n",
      "Epoch 294/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5844 - accuracy: 0.7364 - val_loss: 1.4441 - val_accuracy: 0.6667\n",
      "Epoch 295/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5720 - accuracy: 0.7442 - val_loss: 1.4695 - val_accuracy: 0.6667\n",
      "Epoch 296/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.7597 - val_loss: 1.4847 - val_accuracy: 0.5952\n",
      "Epoch 297/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6302 - accuracy: 0.7287 - val_loss: 1.4791 - val_accuracy: 0.6429\n",
      "Epoch 298/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5769 - accuracy: 0.7364 - val_loss: 1.3915 - val_accuracy: 0.5952\n",
      "Epoch 299/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6432 - accuracy: 0.6744 - val_loss: 1.4924 - val_accuracy: 0.6667\n",
      "Epoch 300/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7364 - val_loss: 1.4077 - val_accuracy: 0.6667\n",
      "Epoch 301/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7132 - accuracy: 0.6977 - val_loss: 1.4055 - val_accuracy: 0.6667\n",
      "Epoch 302/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.7597 - val_loss: 1.6093 - val_accuracy: 0.5714\n",
      "Epoch 303/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5960 - accuracy: 0.7519 - val_loss: 1.5797 - val_accuracy: 0.6667\n",
      "Epoch 304/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.7519 - val_loss: 1.5224 - val_accuracy: 0.6429\n",
      "Epoch 305/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5920 - accuracy: 0.7519 - val_loss: 1.5363 - val_accuracy: 0.6667\n",
      "Epoch 306/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5730 - accuracy: 0.7442 - val_loss: 1.4328 - val_accuracy: 0.6429\n",
      "Epoch 307/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.7442 - val_loss: 1.5319 - val_accuracy: 0.6667\n",
      "Epoch 308/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5825 - accuracy: 0.7287 - val_loss: 1.5228 - val_accuracy: 0.5714\n",
      "Epoch 309/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6548 - accuracy: 0.6899 - val_loss: 1.5812 - val_accuracy: 0.6667\n",
      "Epoch 310/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5648 - accuracy: 0.7597 - val_loss: 1.4627 - val_accuracy: 0.6429\n",
      "Epoch 311/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5609 - accuracy: 0.7674 - val_loss: 1.4995 - val_accuracy: 0.6667\n",
      "Epoch 312/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5541 - accuracy: 0.7597 - val_loss: 1.5386 - val_accuracy: 0.6429\n",
      "Epoch 313/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.7287 - val_loss: 1.6364 - val_accuracy: 0.6667\n",
      "Epoch 314/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6012 - accuracy: 0.7132 - val_loss: 1.4940 - val_accuracy: 0.5952\n",
      "Epoch 315/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6071 - accuracy: 0.7054 - val_loss: 1.5212 - val_accuracy: 0.6429\n",
      "Epoch 316/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5736 - accuracy: 0.7364 - val_loss: 1.5301 - val_accuracy: 0.6667\n",
      "Epoch 317/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7031 - accuracy: 0.6822 - val_loss: 1.5736 - val_accuracy: 0.6667\n",
      "Epoch 318/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5681 - accuracy: 0.7519 - val_loss: 1.5308 - val_accuracy: 0.6667\n",
      "Epoch 319/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7597 - val_loss: 1.5625 - val_accuracy: 0.6905\n",
      "Epoch 320/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5545 - accuracy: 0.7597 - val_loss: 1.5420 - val_accuracy: 0.5952\n",
      "Epoch 321/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5792 - accuracy: 0.7364 - val_loss: 1.5275 - val_accuracy: 0.6429\n",
      "Epoch 322/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7597 - val_loss: 1.4795 - val_accuracy: 0.6667\n",
      "Epoch 323/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7674 - val_loss: 1.4897 - val_accuracy: 0.5952\n",
      "Epoch 324/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6865 - accuracy: 0.6899 - val_loss: 1.6354 - val_accuracy: 0.6667\n",
      "Epoch 325/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.7287 - val_loss: 1.5710 - val_accuracy: 0.6905\n",
      "Epoch 326/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6505 - accuracy: 0.7054 - val_loss: 1.6833 - val_accuracy: 0.6429\n",
      "Epoch 327/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7059 - accuracy: 0.6434 - val_loss: 1.6154 - val_accuracy: 0.6667\n",
      "Epoch 328/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5675 - accuracy: 0.7674 - val_loss: 1.5226 - val_accuracy: 0.6667\n",
      "Epoch 329/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5505 - accuracy: 0.7519 - val_loss: 1.5235 - val_accuracy: 0.6667\n",
      "Epoch 330/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5471 - accuracy: 0.7674 - val_loss: 1.4841 - val_accuracy: 0.6667\n",
      "Epoch 331/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7519 - val_loss: 1.5655 - val_accuracy: 0.6667\n",
      "Epoch 332/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7597 - val_loss: 1.5429 - val_accuracy: 0.6667\n",
      "Epoch 333/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5426 - accuracy: 0.7597 - val_loss: 1.6129 - val_accuracy: 0.6667\n",
      "Epoch 334/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7674 - val_loss: 1.6024 - val_accuracy: 0.6190\n",
      "Epoch 335/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.2955 - accuracy: 0.6899 - val_loss: 2.1705 - val_accuracy: 0.5000\n",
      "Epoch 336/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.0093 - accuracy: 0.6124 - val_loss: 2.1463 - val_accuracy: 0.4524\n",
      "Epoch 337/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.8914 - accuracy: 0.5736 - val_loss: 1.5771 - val_accuracy: 0.5952\n",
      "Epoch 338/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6456 - accuracy: 0.7364 - val_loss: 1.4053 - val_accuracy: 0.5714\n",
      "Epoch 339/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6200 - accuracy: 0.7287 - val_loss: 1.4007 - val_accuracy: 0.6190\n",
      "Epoch 340/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.7287 - val_loss: 1.4021 - val_accuracy: 0.5952\n",
      "Epoch 341/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5972 - accuracy: 0.7597 - val_loss: 1.4774 - val_accuracy: 0.6429\n",
      "Epoch 342/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5949 - accuracy: 0.7287 - val_loss: 1.3857 - val_accuracy: 0.6667\n",
      "Epoch 343/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5929 - accuracy: 0.7597 - val_loss: 1.3997 - val_accuracy: 0.6429\n",
      "Epoch 344/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.7364 - val_loss: 1.3935 - val_accuracy: 0.6429\n",
      "Epoch 345/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7829 - val_loss: 1.3897 - val_accuracy: 0.6667\n",
      "Epoch 346/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7364 - val_loss: 1.4800 - val_accuracy: 0.6667\n",
      "Epoch 347/512\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5491 - accuracy: 0.7752 - val_loss: 1.3967 - val_accuracy: 0.6667\n",
      "Epoch 348/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7752 - val_loss: 1.3703 - val_accuracy: 0.6667\n",
      "Epoch 349/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.7597 - val_loss: 1.2955 - val_accuracy: 0.6667\n",
      "Epoch 350/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.7287 - val_loss: 1.7430 - val_accuracy: 0.6190\n",
      "Epoch 351/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7306 - accuracy: 0.6977 - val_loss: 1.9628 - val_accuracy: 0.5952\n",
      "Epoch 352/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.0823 - accuracy: 0.6434 - val_loss: 1.7514 - val_accuracy: 0.5238\n",
      "Epoch 353/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.0557 - accuracy: 0.7054 - val_loss: 2.0044 - val_accuracy: 0.5238\n",
      "Epoch 354/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7876 - accuracy: 0.6512 - val_loss: 1.5434 - val_accuracy: 0.5000\n",
      "Epoch 355/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6967 - accuracy: 0.6744 - val_loss: 1.3827 - val_accuracy: 0.6429\n",
      "Epoch 356/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.7054 - val_loss: 1.3322 - val_accuracy: 0.6667\n",
      "Epoch 357/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.7209 - val_loss: 1.4748 - val_accuracy: 0.5714\n",
      "Epoch 358/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6571 - accuracy: 0.6899 - val_loss: 1.5381 - val_accuracy: 0.6667\n",
      "Epoch 359/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6839 - accuracy: 0.6822 - val_loss: 1.4133 - val_accuracy: 0.5714\n",
      "Epoch 360/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6545 - accuracy: 0.6512 - val_loss: 1.4846 - val_accuracy: 0.6667\n",
      "Epoch 361/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6629 - accuracy: 0.7054 - val_loss: 1.3951 - val_accuracy: 0.6429\n",
      "Epoch 362/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.6977 - val_loss: 1.2393 - val_accuracy: 0.6667\n",
      "Epoch 363/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6062 - accuracy: 0.7752 - val_loss: 1.3558 - val_accuracy: 0.6190\n",
      "Epoch 364/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5795 - accuracy: 0.7674 - val_loss: 1.3792 - val_accuracy: 0.6429\n",
      "Epoch 365/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5795 - accuracy: 0.7442 - val_loss: 1.4424 - val_accuracy: 0.6667\n",
      "Epoch 366/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5677 - accuracy: 0.7829 - val_loss: 1.4325 - val_accuracy: 0.6667\n",
      "Epoch 367/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5736 - accuracy: 0.7597 - val_loss: 1.4342 - val_accuracy: 0.6429\n",
      "Epoch 368/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.7829 - val_loss: 1.4465 - val_accuracy: 0.6667\n",
      "Epoch 369/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5737 - accuracy: 0.7519 - val_loss: 1.4559 - val_accuracy: 0.6667\n",
      "Epoch 370/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7674 - val_loss: 1.3940 - val_accuracy: 0.6429\n",
      "Epoch 371/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.7674 - val_loss: 1.5216 - val_accuracy: 0.6429\n",
      "Epoch 372/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5664 - accuracy: 0.7519 - val_loss: 1.3583 - val_accuracy: 0.6429\n",
      "Epoch 373/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5730 - accuracy: 0.7597 - val_loss: 1.4117 - val_accuracy: 0.6429\n",
      "Epoch 374/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6870 - accuracy: 0.6899 - val_loss: 1.5597 - val_accuracy: 0.6429\n",
      "Epoch 375/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5924 - accuracy: 0.7597 - val_loss: 1.4102 - val_accuracy: 0.6429\n",
      "Epoch 376/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.7752 - val_loss: 1.4533 - val_accuracy: 0.6667\n",
      "Epoch 377/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6639 - accuracy: 0.7209 - val_loss: 1.2977 - val_accuracy: 0.6190\n",
      "Epoch 378/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6323 - accuracy: 0.7364 - val_loss: 1.5609 - val_accuracy: 0.5714\n",
      "Epoch 379/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.7132 - val_loss: 1.6729 - val_accuracy: 0.5714\n",
      "Epoch 380/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5699 - accuracy: 0.7752 - val_loss: 1.5940 - val_accuracy: 0.6667\n",
      "Epoch 381/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.7209 - val_loss: 1.5014 - val_accuracy: 0.6429\n",
      "Epoch 382/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.7442 - val_loss: 1.4436 - val_accuracy: 0.6667\n",
      "Epoch 383/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5825 - accuracy: 0.7364 - val_loss: 1.3055 - val_accuracy: 0.7143\n",
      "Epoch 384/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.7364 - val_loss: 1.4024 - val_accuracy: 0.5238\n",
      "Epoch 385/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7087 - accuracy: 0.6589 - val_loss: 1.6227 - val_accuracy: 0.5952\n",
      "Epoch 386/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.6589 - val_loss: 1.4279 - val_accuracy: 0.5952\n",
      "Epoch 387/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.6744 - val_loss: 1.4023 - val_accuracy: 0.6667\n",
      "Epoch 388/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5702 - accuracy: 0.7287 - val_loss: 1.4066 - val_accuracy: 0.6429\n",
      "Epoch 389/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.7364 - val_loss: 1.6422 - val_accuracy: 0.6190\n",
      "Epoch 390/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7626 - accuracy: 0.7209 - val_loss: 1.4286 - val_accuracy: 0.6667\n",
      "Epoch 391/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.7209 - val_loss: 1.5596 - val_accuracy: 0.6429\n",
      "Epoch 392/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6899 - val_loss: 1.5594 - val_accuracy: 0.6429\n",
      "Epoch 393/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7597 - val_loss: 1.4831 - val_accuracy: 0.6429\n",
      "Epoch 394/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.6822 - val_loss: 1.3302 - val_accuracy: 0.6667\n",
      "Epoch 395/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.7597 - val_loss: 1.3664 - val_accuracy: 0.7143\n",
      "Epoch 396/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5534 - accuracy: 0.7674 - val_loss: 1.3258 - val_accuracy: 0.5952\n",
      "Epoch 397/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.6899 - val_loss: 1.3928 - val_accuracy: 0.6667\n",
      "Epoch 398/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.7209 - val_loss: 1.2384 - val_accuracy: 0.6190\n",
      "Epoch 399/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5988 - accuracy: 0.7442 - val_loss: 1.3682 - val_accuracy: 0.6667\n",
      "Epoch 400/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.7597 - val_loss: 1.5690 - val_accuracy: 0.6429\n",
      "Epoch 401/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.7442 - val_loss: 1.6064 - val_accuracy: 0.6190\n",
      "Epoch 402/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.7752 - val_loss: 1.4697 - val_accuracy: 0.6190\n",
      "Epoch 403/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5610 - accuracy: 0.7829 - val_loss: 1.4816 - val_accuracy: 0.6667\n",
      "Epoch 404/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5623 - accuracy: 0.7519 - val_loss: 1.4294 - val_accuracy: 0.6429\n",
      "Epoch 405/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.7752 - val_loss: 1.5375 - val_accuracy: 0.6429\n",
      "Epoch 406/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7519 - val_loss: 1.4902 - val_accuracy: 0.6429\n",
      "Epoch 407/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7442 - val_loss: 1.5141 - val_accuracy: 0.6667\n",
      "Epoch 408/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7519 - val_loss: 1.4738 - val_accuracy: 0.6667\n",
      "Epoch 409/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7829 - val_loss: 1.5419 - val_accuracy: 0.6667\n",
      "Epoch 410/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5469 - accuracy: 0.7907 - val_loss: 1.5513 - val_accuracy: 0.6429\n",
      "Epoch 411/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7907 - val_loss: 1.6073 - val_accuracy: 0.6667\n",
      "Epoch 412/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.7364 - val_loss: 1.3859 - val_accuracy: 0.5952\n",
      "Epoch 413/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5675 - accuracy: 0.7442 - val_loss: 1.5013 - val_accuracy: 0.6190\n",
      "Epoch 414/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.7364 - val_loss: 1.7492 - val_accuracy: 0.6667\n",
      "Epoch 415/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.7132 - val_loss: 1.6295 - val_accuracy: 0.5238\n",
      "Epoch 416/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6052 - accuracy: 0.7209 - val_loss: 1.4783 - val_accuracy: 0.6667\n",
      "Epoch 417/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5635 - accuracy: 0.7752 - val_loss: 1.5183 - val_accuracy: 0.6429\n",
      "Epoch 418/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7657 - accuracy: 0.6357 - val_loss: 1.5703 - val_accuracy: 0.6429\n",
      "Epoch 419/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6367 - accuracy: 0.6822 - val_loss: 1.5050 - val_accuracy: 0.5476\n",
      "Epoch 420/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5779 - accuracy: 0.7287 - val_loss: 1.6533 - val_accuracy: 0.6429\n",
      "Epoch 421/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.7829 - val_loss: 1.6730 - val_accuracy: 0.5714\n",
      "Epoch 422/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5814 - accuracy: 0.7364 - val_loss: 1.7486 - val_accuracy: 0.6190\n",
      "Epoch 423/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5621 - accuracy: 0.7364 - val_loss: 1.5262 - val_accuracy: 0.6190\n",
      "Epoch 424/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6680 - accuracy: 0.7132 - val_loss: 1.5407 - val_accuracy: 0.6190\n",
      "Epoch 425/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7171 - accuracy: 0.6744 - val_loss: 1.2862 - val_accuracy: 0.6905\n",
      "Epoch 426/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6521 - accuracy: 0.7597 - val_loss: 1.3693 - val_accuracy: 0.6667\n",
      "Epoch 427/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.7364 - val_loss: 1.4837 - val_accuracy: 0.6429\n",
      "Epoch 428/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5953 - accuracy: 0.7442 - val_loss: 1.6525 - val_accuracy: 0.6667\n",
      "Epoch 429/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5559 - accuracy: 0.7752 - val_loss: 1.7090 - val_accuracy: 0.5952\n",
      "Epoch 430/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5843 - accuracy: 0.7674 - val_loss: 1.8857 - val_accuracy: 0.5952\n",
      "Epoch 431/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.7364 - val_loss: 1.6842 - val_accuracy: 0.6667\n",
      "Epoch 432/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.6977 - val_loss: 1.4418 - val_accuracy: 0.6429\n",
      "Epoch 433/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7752 - val_loss: 1.3801 - val_accuracy: 0.6667\n",
      "Epoch 434/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7752 - val_loss: 1.3679 - val_accuracy: 0.6667\n",
      "Epoch 435/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7674 - val_loss: 1.4604 - val_accuracy: 0.6429\n",
      "Epoch 436/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5826 - accuracy: 0.7287 - val_loss: 1.5304 - val_accuracy: 0.6429\n",
      "Epoch 437/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7829 - val_loss: 1.4283 - val_accuracy: 0.6429\n",
      "Epoch 438/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.7752 - val_loss: 1.5079 - val_accuracy: 0.6667\n",
      "Epoch 439/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7674 - val_loss: 1.5074 - val_accuracy: 0.5952\n",
      "Epoch 440/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7519 - val_loss: 1.7769 - val_accuracy: 0.5714\n",
      "Epoch 441/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.8744 - accuracy: 0.6047 - val_loss: 1.7991 - val_accuracy: 0.5714\n",
      "Epoch 442/512\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5808 - accuracy: 0.7054 - val_loss: 1.5767 - val_accuracy: 0.5476\n",
      "Epoch 443/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5911 - accuracy: 0.7209 - val_loss: 1.5184 - val_accuracy: 0.6905\n",
      "Epoch 444/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5561 - accuracy: 0.7519 - val_loss: 1.4551 - val_accuracy: 0.6190\n",
      "Epoch 445/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5645 - accuracy: 0.7519 - val_loss: 1.5004 - val_accuracy: 0.6667\n",
      "Epoch 446/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5279 - accuracy: 0.7674 - val_loss: 1.4453 - val_accuracy: 0.6667\n",
      "Epoch 447/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5587 - accuracy: 0.7907 - val_loss: 1.2335 - val_accuracy: 0.7143\n",
      "Epoch 448/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5451 - accuracy: 0.7752 - val_loss: 1.4163 - val_accuracy: 0.6190\n",
      "Epoch 449/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.6977 - val_loss: 1.5158 - val_accuracy: 0.6190\n",
      "Epoch 450/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6144 - accuracy: 0.7442 - val_loss: 1.6186 - val_accuracy: 0.6190\n",
      "Epoch 451/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.6744 - val_loss: 1.5804 - val_accuracy: 0.5952\n",
      "Epoch 452/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6809 - accuracy: 0.6589 - val_loss: 1.6448 - val_accuracy: 0.5952\n",
      "Epoch 453/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5823 - accuracy: 0.7519 - val_loss: 1.5285 - val_accuracy: 0.6190\n",
      "Epoch 454/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.7519 - val_loss: 1.4666 - val_accuracy: 0.6429\n",
      "Epoch 455/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5621 - accuracy: 0.7597 - val_loss: 1.4010 - val_accuracy: 0.6905\n",
      "Epoch 456/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.7239 - accuracy: 0.6667 - val_loss: 1.5613 - val_accuracy: 0.6429\n",
      "Epoch 457/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5959 - accuracy: 0.7209 - val_loss: 1.5315 - val_accuracy: 0.6429\n",
      "Epoch 458/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.6744 - val_loss: 1.7463 - val_accuracy: 0.5952\n",
      "Epoch 459/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7258 - accuracy: 0.6512 - val_loss: 1.6006 - val_accuracy: 0.5000\n",
      "Epoch 460/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6434 - val_loss: 1.4565 - val_accuracy: 0.5476\n",
      "Epoch 461/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6044 - accuracy: 0.7054 - val_loss: 1.4816 - val_accuracy: 0.6667\n",
      "Epoch 462/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5591 - accuracy: 0.7597 - val_loss: 1.5181 - val_accuracy: 0.6905\n",
      "Epoch 463/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.7674 - val_loss: 1.5181 - val_accuracy: 0.6667\n",
      "Epoch 464/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7519 - val_loss: 1.4496 - val_accuracy: 0.6905\n",
      "Epoch 465/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7364 - val_loss: 1.5058 - val_accuracy: 0.6905\n",
      "Epoch 466/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.7519 - val_loss: 1.6186 - val_accuracy: 0.6905\n",
      "Epoch 467/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.6124 - val_loss: 1.6901 - val_accuracy: 0.5714\n",
      "Epoch 468/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5897 - accuracy: 0.7054 - val_loss: 1.4524 - val_accuracy: 0.6905\n",
      "Epoch 469/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6486 - accuracy: 0.6977 - val_loss: 1.4226 - val_accuracy: 0.6905\n",
      "Epoch 470/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6410 - accuracy: 0.6667 - val_loss: 1.4143 - val_accuracy: 0.6429\n",
      "Epoch 471/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.6667 - val_loss: 1.8156 - val_accuracy: 0.5714\n",
      "Epoch 472/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.7442 - val_loss: 1.6206 - val_accuracy: 0.5952\n",
      "Epoch 473/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5699 - accuracy: 0.7287 - val_loss: 1.5979 - val_accuracy: 0.6190\n",
      "Epoch 474/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.7132 - val_loss: 1.3828 - val_accuracy: 0.6190\n",
      "Epoch 475/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5476 - accuracy: 0.7829 - val_loss: 1.7989 - val_accuracy: 0.6429\n",
      "Epoch 476/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.7287 - val_loss: 1.7037 - val_accuracy: 0.6190\n",
      "Epoch 477/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7829 - val_loss: 1.4540 - val_accuracy: 0.6905\n",
      "Epoch 478/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.7752 - val_loss: 1.5517 - val_accuracy: 0.6190\n",
      "Epoch 479/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6743 - accuracy: 0.6822 - val_loss: 1.8653 - val_accuracy: 0.5952\n",
      "Epoch 480/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.7519 - val_loss: 1.7292 - val_accuracy: 0.6667\n",
      "Epoch 481/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7519 - val_loss: 1.5858 - val_accuracy: 0.6667\n",
      "Epoch 482/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7674 - val_loss: 1.6216 - val_accuracy: 0.6190\n",
      "Epoch 483/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5385 - accuracy: 0.7364 - val_loss: 1.6009 - val_accuracy: 0.6667\n",
      "Epoch 484/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7519 - val_loss: 1.5391 - val_accuracy: 0.6429\n",
      "Epoch 485/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7364 - val_loss: 1.4917 - val_accuracy: 0.6667\n",
      "Epoch 486/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.7674 - val_loss: 1.5575 - val_accuracy: 0.6667\n",
      "Epoch 487/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7442 - val_loss: 1.5159 - val_accuracy: 0.6429\n",
      "Epoch 488/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7829 - val_loss: 1.6604 - val_accuracy: 0.6429\n",
      "Epoch 489/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7287 - val_loss: 1.6053 - val_accuracy: 0.6667\n",
      "Epoch 490/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7519 - val_loss: 1.5944 - val_accuracy: 0.6667\n",
      "Epoch 491/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5252 - accuracy: 0.7364 - val_loss: 1.6478 - val_accuracy: 0.6667\n",
      "Epoch 492/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.7829 - val_loss: 1.5939 - val_accuracy: 0.6667\n",
      "Epoch 493/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.7597 - val_loss: 1.6341 - val_accuracy: 0.6667\n",
      "Epoch 494/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7674 - val_loss: 1.6401 - val_accuracy: 0.6667\n",
      "Epoch 495/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.7519 - val_loss: 1.5858 - val_accuracy: 0.6667\n",
      "Epoch 496/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7674 - val_loss: 1.7006 - val_accuracy: 0.6667\n",
      "Epoch 497/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7442 - val_loss: 1.6508 - val_accuracy: 0.6429\n",
      "Epoch 498/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7597 - val_loss: 1.8387 - val_accuracy: 0.6905\n",
      "Epoch 499/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.7364 - val_loss: 1.6254 - val_accuracy: 0.6429\n",
      "Epoch 500/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7829 - val_loss: 1.6619 - val_accuracy: 0.6667\n",
      "Epoch 501/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7984 - val_loss: 1.6543 - val_accuracy: 0.6190\n",
      "Epoch 502/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7442 - val_loss: 1.8164 - val_accuracy: 0.6429\n",
      "Epoch 503/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5545 - accuracy: 0.7364 - val_loss: 1.6132 - val_accuracy: 0.6905\n",
      "Epoch 504/512\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4693 - accuracy: 0.7829 - val_loss: 1.6859 - val_accuracy: 0.6905\n",
      "Epoch 505/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5787 - accuracy: 0.7442 - val_loss: 1.7283 - val_accuracy: 0.6190\n",
      "Epoch 506/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5563 - accuracy: 0.7674 - val_loss: 1.6325 - val_accuracy: 0.6667\n",
      "Epoch 507/512\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5441 - accuracy: 0.7209 - val_loss: 1.6818 - val_accuracy: 0.6667\n",
      "Epoch 508/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5565 - accuracy: 0.7519 - val_loss: 1.7067 - val_accuracy: 0.6905\n",
      "Epoch 509/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5898 - accuracy: 0.7519 - val_loss: 1.8519 - val_accuracy: 0.6905\n",
      "Epoch 510/512\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7519 - val_loss: 1.9517 - val_accuracy: 0.6429\n",
      "Epoch 511/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5684 - accuracy: 0.7364 - val_loss: 1.5853 - val_accuracy: 0.6667\n",
      "Epoch 512/512\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.6977 - val_loss: 2.0245 - val_accuracy: 0.6905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ee7616bc0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=512,batch_size=16,validation_split=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9708f8c3-fd4b-4f71-b2b4-179116004194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.9314 - accuracy: 0.6744 - 31ms/epoch - 16ms/step\n",
      "Test accuracy: 0.674\n",
      "Test loss: 0.931\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test,y_test,verbose=2)\n",
    "print(f'Test accuracy: {test_acc:.3f}')\n",
    "print(f'Test loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f0cd35f-0ed6-4058-bdfe-2146284095e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "Predicted classes: [0 6 0 6 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "predictions = model.predict(x_test[:5])\n",
    "predicted_classes = tf.argmax(predictions, axis=1)\n",
    "print(\"Predicted classes:\", predicted_classes.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c2fa904-aa38-4f2d-af10-23acc6b3329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.51755</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.51727</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.34</td>\n",
       "      <td>73.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.52152</td>\n",
       "      <td>13.05</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.87</td>\n",
       "      <td>72.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>9.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba    Fe\n",
       "9    1.51755  13.00  3.60  1.36  72.99  0.57  8.40  0.00  0.11\n",
       "197  1.51727  14.70  0.00  2.34  73.28  0.00  8.95  0.66  0.00\n",
       "66   1.52152  13.05  3.65  0.87  72.22  0.19  9.85  0.00  0.17"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1af4927-be61-449b-a1e5-1d5c1b3258d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin1 = x_test.iloc[[0]]\n",
    "sonuc1 = model.predict(tahmin1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffb75331-03bc-45b1-b720-7030d4898ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuc1.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c140716b-c162-4cc7-85cd-ab25e381346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin2 = x_test.iloc[[1]]\n",
    "sonuc2 = model.predict(tahmin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c352284-bbcf-4a3e-adc4-ed1afbc53225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuc2.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b426b8cd-065f-4fae-ab48-c2ceff4bee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin3 = x_test.iloc[[2]]\n",
    "sonuc3 = model.predict(tahmin3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0778d647-9f1e-4fbe-9b1e-d1f32817e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuc3.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dcbd887f-0473-4d5d-aab5-51bea5aca4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin4 = x_test.iloc[[4]]\n",
    "sonuc4 = model.predict(tahmin4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ece091b2-21fd-4f5a-af8e-3707c7358382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonuc4.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "830debbc-ee6e-4c8b-ac6f-736650b5eb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2cfb7-f65f-474b-86fc-b368829bc281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
